{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "\n",
    "import chat as chat\n",
    "import data as data\n",
    "import utility as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our data -- the load_challenge_moves_csv function also processes the csv load so move / win probability are lists rather than strings\n",
    "train_df = data.loader.load_challenge_moves_csv(\"data/chess_challenges_train_10k.csv\", shuffle=True)\n",
    "\n",
    "train_iterator = itertools.cycle(train_df.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_chess_model(ollama_session, train_iterator, system_prompt, board_representation, move_representation, with_piece, max_iters=None, max_timeout=30, verbose=False):\n",
    "    evaluation_results = {\n",
    "        \"num_attempts\": 0,\n",
    "        \"legal_move_ranks\": [],\n",
    "        \"num_legal_moves\": 0,\n",
    "        \"error_illegal_move\": 0,\n",
    "        \"error_timeout\": 0,\n",
    "        \"error_generation\": 0,\n",
    "        \"error_extraction\": 0,\n",
    "    }\n",
    "\n",
    "    for iter in range(max_iters):\n",
    "        evaluation_results[\"num_attempts\"] += 1\n",
    "        try:\n",
    "            _, row = next(train_iterator)\n",
    "            board = row[\"FEN\"]\n",
    "            legal_moves = row[\"Move\"]\n",
    "\n",
    "            piece_letter, piece_position = util.get_random_piece_and_position(board)\n",
    "\n",
    "            legal_piece_moves = util.get_legal_moves(board, piece_position, move_representation)\n",
    "\n",
    "            #pass proper argumements: board, board_representation, move_type...\n",
    "            # if with piece send piece_letter\n",
    "            prompt = chat.format_prompt_for_legal_move(board, board_representation, piece_letter, piece_position, move_representation)\n",
    "            \n",
    "            # Generate a response from the model\n",
    "            response, runtime_results = ollama_session.chat_baseline(system_prompt = system_prompt, user_prompt=prompt, timeout=max_timeout)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{'-'*100}\\nPrompt:\\n{prompt}\\n\\nResponse:\\n{response}\\n\\nRuntime Results:\\n{runtime_results}\\n{'-'*100}\\n\")\n",
    "                util.visualize_board_ipynb(row[\"FEN\"])\n",
    "\n",
    "            moves = chat.extract_legal_moves(response)\n",
    "\n",
    "            correct_moves, illegal_moves = util.compare_moves_and_legal_moves(moves, legal_moves)\n",
    "            \n",
    "            #update evaluation results\n",
    "\n",
    "            \n",
    "            # If move in legal moves print probability / move ranking\n",
    "            # evaluation_results[\"num_legal_moves\"] += 1\n",
    "            tps = runtime_results[\"generated_tokens\"] / runtime_results[\"generation_duration\"]\n",
    "            print(f\"[{iter+1:<4}/{max_iters:<4}] Move: {moves} | Correct Ratio: {len(correct_moves)} / {len(legal_moves)} | Illegal Raio: {len(illegal_moves)} / {len(moves)} | TPS: {tps:.2f}\")\n",
    "            # evaluation_results['legal_move_ranks'].append((move_idx+1)/len(legal_moves))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{iter+1:<4}/{max_iters:<4}] {type(e).__name__}: {e}\")\n",
    "            if type(e) == chat.IllegalMoveError:\n",
    "                evaluation_results[\"error_illegal_move\"] += 1\n",
    "            elif type(e) == chat.TimeoutError:\n",
    "                evaluation_results[\"error_timeout\"] += 1\n",
    "            elif type(e) == chat.GenerationError:\n",
    "                evaluation_results[\"error_generation\"] += 1\n",
    "            elif type(e) == chat.ExtractionError:\n",
    "                evaluation_results[\"error_extraction\"] += 1\n",
    "            else:\n",
    "                print(f\"Unknown Error: {e}\")\n",
    "\n",
    "    # At end print out results\n",
    "    avg_rank = sum(evaluation_results['legal_move_ranks'])/len(evaluation_results['legal_move_ranks']) if len(evaluation_results['legal_move_ranks']) else 0\n",
    "    print(f\"\\n{'='*60}\\nAverage Legal Move Score (Rank / Total Moves):\\n{avg_rank:.4f}\\n\")\n",
    "    print(f\"Evaluation Results:\\n\")\n",
    "    for key, value in evaluation_results.items():\n",
    "        if key != \"legal_move_ranks\":\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1   /1   ] KeyError: 'message'\n",
      "Unknown Error: 'message'\n",
      "\n",
      "============================================================\n",
      "Average Legal Move Score (Rank / Total Moves):\n",
      "0.0000\n",
      "\n",
      "Evaluation Results:\n",
      "\n",
      "num_attempts: 1\n",
      "num_legal_moves: 0\n",
      "error_illegal_move: 0\n",
      "error_timeout: 0\n",
      "error_generation: 0\n",
      "error_extraction: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a new Ollama Session to allow us to chat w/ various models\n",
    "# IMPORTANT: Make sure to call `ollama serve` in your terminal to start the Ollama server\n",
    "# [Lucas]: I'm personally getting ~70TPS on 1.5b and ~7TPS on 7b on my laptop. Most responses are between 1000-2000 tokens.\n",
    "model_name = \"deepseek-r1:1.5b\"       # {deepseek-r1:1.5b, deepseek-r1:7b}\n",
    "board_rep = \"grid\" # {grid, desc, FEN}\n",
    "ollama_session = chat.OllamaSession(model=model_name, use_cuda=False, board_representation= board_rep)\n",
    "\n",
    "evaluate_chess_model(\n",
    "    ollama_session = ollama_session, \n",
    "    train_iterator = train_iterator, \n",
    "    board_representation = board_rep,\n",
    "    max_iters = 1,\n",
    "    max_timeout = 200,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
