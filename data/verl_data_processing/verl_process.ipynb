{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data for veRL\n",
    "---\n",
    "High level what we need here:\n",
    "- veRL requires the data in parquet format (type of data file)\n",
    "- The data needs to be stored in a specific format w/ specific column names\n",
    "- We also need to make sure to apply certain json.dumps calls to make sure the nested dicts are loadable in veRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First need to load in our data (csv) -- use this function. Can also specify # of samples to load in\n",
    "DATA_ROOT = os.path.abspath(os.path.join(os.path.abspath(os.getcwd()), \"..\"))\n",
    "\n",
    "def _load_challenge_moves_csv(filename: str, shuffle: bool = True, max_samples: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a CSV file into a pandas DataFrame, converts list-like string columns into actual lists,\n",
    "    removes single apostrophes from 'Move' column values, and optionally shuffles the DataFrame.\n",
    "    Allows limiting the number of rows returned.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Name of csv file in the 'raw_data' folder.\n",
    "        shuffle (bool): Whether to shuffle the DataFrame (default is True).\n",
    "        max_samples (int, optional): Maximum number of rows to return. If None, returns all rows.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Get 'data_root' using absolute paths and moving back one folder\n",
    "    df = pd.read_csv(os.path.join(DATA_ROOT, \"raw_data\", filename))\n",
    "\n",
    "    # Convert the columns from strings to lists (using ast.literal_eval)    \n",
    "    df[\"Move\"] = df[\"Move\"].apply(lambda x: [move.replace(\"'\", \"\") for move in ast.literal_eval(x)])\n",
    "    df[\"Win Probability\"] = df[\"Win Probability\"].apply(ast.literal_eval)\n",
    "\n",
    "    # Optional processing (based on args)\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    if max_samples is not None:\n",
    "        df = df.head(max_samples)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various processing functions\n",
    "# ========================================================\n",
    "\n",
    "# Top-level processing function that we can apply to each row of our csv dataset\n",
    "def process_fn(example, idx, split):\n",
    "    \"\"\"\n",
    "    Processes a single row in the dataset.\n",
    "\n",
    "    Args:\n",
    "        example (pd.Series): A row from the DataFrame.\n",
    "        idx (int): The index of the row.\n",
    "        split (str): The dataset split ('train' or 'test').\n",
    "\n",
    "    Returns:\n",
    "        dict: Processed row in the desired format.\n",
    "    \"\"\"\n",
    "    question = format_prompt(board=example['FEN'], legal_moves=example['Move'])\n",
    "    solution = create_reward_dict(move=example['Move'], win_prob=example['Win Probability'])\n",
    "\n",
    "    return {\n",
    "        \"data_source\": \"chess_reasoning\",\n",
    "        \"prompt\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question,\n",
    "        }],\n",
    "        \"ability\": \"math\",\n",
    "        \"reward_model\": {\n",
    "            \"style\": \"rule\",\n",
    "            \"ground_truth\": solution\n",
    "        },\n",
    "        \"extra_info\": {\n",
    "            'split': split,\n",
    "            'index': idx\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# Functions to create our reward dict -- can update this to try different reward funcs\n",
    "def create_reward_dict(move: List[str], win_prob: List[float]) -> dict:\n",
    "    \"\"\"\n",
    "    Takes in two lists -- a list of legal moves and a list of associated win probabilities.\n",
    "    Zips them together into a NumPy array, normalizes the win probabilities using min-max scaling \n",
    "    so that they lie between 0 and 1, and returns a dictionary mapping each move to its normalized win probability.\n",
    "    \"\"\"\n",
    "    # Create a numpy array from the zipped moves and win probabilities.\n",
    "    arr = np.array(list(zip(move, win_prob)), dtype=object)\n",
    "    \n",
    "    # Extract the win probability values and convert to float.\n",
    "    win_probs = np.array(arr[:, 1], dtype=float)\n",
    "    \n",
    "    # Apply min-max normalization.\n",
    "    min_val = win_probs.min()\n",
    "    max_val = win_probs.max()\n",
    "    if max_val - min_val > 0:\n",
    "        normalized_win_probs = (win_probs - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        # If all values are the same, set them to 0.5.\n",
    "        normalized_win_probs = np.full_like(win_probs, 0.5)\n",
    "    \n",
    "    # Create a dictionary mapping each move to its normalized win probability.\n",
    "    reward_dict = {m: float(p) for m, p in zip(arr[:, 0], normalized_win_probs)}\n",
    "    return reward_dict\n",
    "\n",
    "\n",
    "# Functions to process / output our prompt from the initial data in the master csv\n",
    "SYSTEM_PROMPT = \"\"\"<|im_start|>system\n",
    "You are a smart, strategic, and wise chess reasoning model. You are currently in a chess tournament where you have 1 minute to make a move.\n",
    "\n",
    "We will provide you with a board in Forsyth-Edwards Notation (FEN) and a list of legal moves. Your task is to reason through the board state and determine an optimal move based on your analysis.\n",
    "\n",
    "The reasoning process and answer must be enclosed within <think> </think> and <answer> </answer> tags, respectively. For example, when given an input prefixed with \"user:\", your response should be in the format \"assistant: <think> [your reasoning] </think> <answer> [chosen move] </answer>\".\n",
    "\n",
    "Below is an example of your desired behavior:\n",
    "\n",
    "Example 1:\n",
    "user: <FEN> 7R/4n1k1/4P3/1pp2B2/8/6P1/2r4P/6K1 w - - 3 50 </FEN> <legal moves> [f5h7, h8h6, h2h4, h8g8, h2h3, g1f1, f5d3, f5h3, h8b8, h8h4, h8c8, h8f8, h8a8, h8d8, f5g4, h8h3, g3g4, g1h1, f5e4, h8h5, f5c2, h8e8, f5g6, h8h7] </legal moves>\n",
    "assistant: <think> Playing as white, I'm in the offensive here. My rook is currently in at risk of being taken by their king and my bishop is at risk of being taken by their knight. I could take their rook with their bishop but they would take my rook. However, if I move my rook to h7, I'll put their king in check while saving my rook and bishop and continue pressure. Moving rook h8 to h7 is a wise move. </think> <answer> h8h7 </answer>\n",
    "\n",
    "Make sure that your chosen move is in standard chess notation (such as 'g8f7' -- which means you move the piece from g8 to f7). \n",
    "\n",
    "Use English for your thought process. Remember you have one minute to move so be quick.<|im_end|>\"\"\"\n",
    "\n",
    "def format_prompt(board: str, legal_moves: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Formats the board and legal moves into a prompt for the model.\n",
    "    \n",
    "    Args:\n",
    "        board (str): The current board state.\n",
    "        legal_moves (List[str]): The list of legal moves.\n",
    "    \n",
    "    Returns:\n",
    "        str: The formatted prompt.\n",
    "    \"\"\"\n",
    "    random.shuffle(legal_moves)\n",
    "    prompt = f\"<|im_start|>user: <FEN> {board} </FEN> <legalmoves> {legal_moves} </legalmoves><|im_end|>\\n<|im_start|>assistant: \"\n",
    "    prompt = prompt.replace(\"'\", \"\")\n",
    "    return SYSTEM_PROMPT + '\\n' + prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load and process our data -- saves as parquet\n",
    "experiment_name = \"old_system_prompt\"\n",
    "max_samples = 5000   # Let's use 5k max samples for now; no need to do a val set for now as well\n",
    "test_samples = 256   # Keep as is -- want this smol\n",
    "\n",
    "# Apply transformation to train and test datasets\n",
    "# If we want to be super careful we can actually pre-split into train / val to make sure no contamination but imo val results not super important but we need something small\n",
    "train_df = _load_challenge_moves_csv(\"chess_challenges_full.csv\", shuffle=True, max_samples=max_samples)\n",
    "train_dataset = train_df.apply(lambda row: process_fn(row, row.name, \"train\"), axis=1)\n",
    "train_dataset = pd.DataFrame(train_dataset.tolist())\n",
    "test_df = _load_challenge_moves_csv(\"chess_challenges_full.csv\", shuffle=True, max_samples=test_samples)\n",
    "test_dataset = test_df.apply(lambda row: process_fn(row, row.name, \"train\"), axis=1)\n",
    "test_dataset = pd.DataFrame(test_dataset.tolist())\n",
    "\n",
    "# Need to fix due to parquet screwing up dicts\n",
    "train_dataset[\"reward_model\"] = train_dataset[\"reward_model\"].apply(json.dumps)\n",
    "test_dataset[\"reward_model\"] = test_dataset[\"reward_model\"].apply(json.dumps)\n",
    "\n",
    "# Save our parquets down\n",
    "train_parquet_filename = f\"train-{experiment_name}-{max_samples//1000}k.parquet\"\n",
    "test_parquet_filename = f\"test-{experiment_name}-{test_samples}.parquet\"\n",
    "train_dataset.to_parquet(os.path.join(DATA_ROOT, \"parquet_datasets\", train_parquet_filename), index=False)\n",
    "test_dataset.to_parquet(os.path.join(DATA_ROOT, \"parquet_datasets\", test_parquet_filename), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess-reasoner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
